### Hi there I'm David üëã


### <a href="https://github.com/brau3654/brau3654.github.io"> St. Paul Crime Database</a>

This project was meant to take a large, complex dataset and turn it into something more user friendly. This accessibility is at both ends of the process. The site has an easy way to enter new crimes. It also has the ability to look at all the crimes and filter through them. A tool loke this (though probably a more robust one) could be used by law enforcement to see trends in crimes committed. Just looking at cases it would be hard to spot patterns, but maybe certain locations have higher rates of certain crimes or certain time periods may have seen spikes in criminal activity. This data could be combined with others to try and predict problems and put measures in place to help potential victims.

---

### <a href="https://github.com/brau3654/STAT360_FinalProject"> Predicting Football Success</a>

This model on its own is just useless. But that really isn't the point of it. This model was meant to demonstrate and be a culmination of our learning about Structural Equation Modeling. This system is meant to take a large quantity of variables and make it useful and understandable. It has the ability to work with covariance in variables and combine them into singular factors in the final model. This type of modeling can be great for people, businesses, or governments. In our example we had 22 variables, but we could group those into 4 factors. In a more real-world scenario, you might take data from a factory and try and see what is causing poor production quality. A model may start with 50 variables but those are then grouped into factors like training, speed, time, breakdowns, etc. With SEM you can perform analysis and come back to the factory and say if you want more production you need to put more emphasis on training. Training could be a factor which was loaded onto variables like number of new hires, number of mistakes, and time spent training. You can easily present to people the idea that poor training quality results in poor product. Then you can go into want variables lead you to this conclusion without just saying, ‚ÄúWell these 14 variables correlated with poor production days. Good Luck!‚Äù This method of analysis is very flexible and can be used in all sorts of environments. 

---

### <a href="https://github.com/brau3654/DeepLearning"> Titanic Survival</a>

This project, like the last, is useless on its own. I don‚Äôt think there is a whole lot of need for the ability to predict who will get off the Titanic alive these days. But what this project did do is force me to learn more about data cleaning and AI. The demand for Artificial Intelligence has seen an incredible increase in the last years and as it is integrated into more systems understanding how it works is all the more important. This model, like a lot of statistics, started with a lot of very messy data. A lot of cases had missing values and impossible values were common as well. Before modeling could even start, I needed to figure out how to filter out good data and fill in the blank spots present within it. 

---
